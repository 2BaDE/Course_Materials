{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515d513a",
   "metadata": {},
   "source": [
    "# 1. What is Data Science? \n",
    "\n",
    "## 1.1 Foundation of Big Data \n",
    "\n",
    "Big Data refers to the dynamic, large and disparate volumns of data being created by peope, tools, and machines. It requires new, inoovative, and scalable technology to collect, host, and analytically process that vast amount of data gathered in order to derive real-time business insights that relate to consumers, risk, profit, performance, productivity management, and enhanced share holder's value. \n",
    "\n",
    "## 1.2 V's of Big Data\n",
    "\n",
    "- Velocity : The speed that which data accumulates \n",
    "- Volume : The scale of the data, or the increase in the amount of data stored. \n",
    "- Variety : The diversity of the data from different souces, machine, peoper, and processes \n",
    "- Veracity : The quality and origin of data, and its conformity to facts and accuracy\n",
    "- Value : Our ability and need to turn data into value\n",
    "\n",
    "## 1.3 Difference in Data Science \n",
    "\n",
    "Data Science is the process and method for extracting knowledge and insights from large volume of disparate data. \n",
    "\n",
    "- Big Data : Dataset that are so massive, so quickly built, and so varied that they defy traditional analysis methods. \n",
    "- Data Mining : The process of automatically searching and analyzing data, discovering previously unrevealed patterns. \n",
    "- Machine Learning : Subset of AI that uses computer algorithms to analyze data and make intelligent decisions based on what it is learned without explicitly programmed and also enables machines to solve problems on their own and make accurate predictions using provided data.\n",
    "- Deep Learning : Specialized subset of machine learning that uses layered neural networks to simulate human decision making. And it enables AI systems to continuously learn on the job and improve the quality and accuracy of results by determining whether decision were correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a22f903",
   "metadata": {},
   "source": [
    "# 2. Tools for Data Science \n",
    "\n",
    "## 2.1 Language \n",
    "\n",
    "We need to study languages on what company we work for, what role we have, and the age of our existing application. \n",
    "\n",
    "- Python\n",
    "- R\n",
    "- SQL\n",
    "- Scala, Java, C++, Julia\n",
    "- Javascript, PHP, Go, Ruby, Visual Basic\n",
    "\n",
    "What we work as Data Scientist? \n",
    "\n",
    "- Business Analyst\n",
    "- Database Engineer\n",
    "- Data Analyst \n",
    "- Data Engineer\n",
    "- Data Scientist \n",
    "- Research Scientist \n",
    "\n",
    "### Python \n",
    "\n",
    "Python is general purpose language and large standard library. For data science, there are three library below : \n",
    "\n",
    "- Scientific computing libraries like Pandas, Numpy, Scipy, and Matplotlib\n",
    "- For AI it has Pytorch, TensorFlow, Keras, Scikit-learn\n",
    "- Python can be used for Natural Language Processing(NLP) using the Natural Language Tool kit(NLTK)\n",
    "\n",
    "### R \n",
    "\n",
    "Unlikely with Python, R is good for minimal year of programming and have very useful packages for data analytic.\n",
    "\n",
    "### SQL \n",
    "\n",
    "SQL is the language useful in handling structured data, and managing data in relational databases. Knowing SQL will help us get jobs as a business and data analyst and is a must in data engineering and data science. When performing operations with SQL, the data is accessed directly. This can considerably speed up workflow executions. SQL is the interpreter between us and the databases. SQL is a ANSI standard, which means if we learn SQL and use if with one database we will be able to easily apply our SQL knowledge with many other databases. \n",
    "\n",
    "## 2.2 Data Science Workflow \n",
    "\n",
    "- Data Management : Process of persisting and retrieving data\n",
    "- Data Integreation and Transformation(ETL) : Process of retrieving data from remote data management systems and transforming data and loading it into a local data management system\n",
    "- Data Visualization : Part of an initial data exploration process\n",
    "- Model Building : Process of creating machine learning or deep learning model using an appropriate algorithm with a lot of data\n",
    "- Model deployment : Making such a machine learning or deep learning model available to third-party applications\n",
    "- Model monitoring and assessment : Ensuring continuous performance quality checks on the deployed model and checking for accuracy, fairness, and adversarial robustness \n",
    "- Code asset management : Versioning and other collaborative features to faciliate team work \n",
    "- Data asset management : Brings the same versioning and collaborative components of data and supprots replication, backup, and access right managment\n",
    "- Deployment environments(IDEs) : Tools that help the data sceientist to implement, execute, test, and deploy their work\n",
    "- Execution environments : Tools where data preprocessing, model training, and deployment take place\n",
    "- Fully integrated, Visual tooling components : Covers all the previous tooling components either partially or completely \n",
    "\n",
    "### Open Soruce Tools for Data Science \n",
    "\n",
    "- Data Management : MySQL, PostgreSQL, NoSQL(MongoDB, Spark CouchDB, Apahce Cassandra), HDFS \n",
    "- Data integreation and Transformation : Apache Airflow, KubeFlow, Apache Kafca, Apache Nifi, Apache SparkSQL, Node red\n",
    "- Data Visualization : Programming Libraries, Hue, Kibana, Apache Superet\n",
    "- Model Deployment : Apache PredictionIO, Seldon, SparkML, TensorFlow \n",
    "- Model monitoring : ModelDB, Prometheus, IBM AI fairness 360 \n",
    "- Code Asset Management : Github, Gitlab, Bitbucket\n",
    "- Data Asset Management : Apache Atlas, ODPI Egeria, Kylo \n",
    "- Deployment Environment : Jupyter Notebook, Apache Zepplin, Rstudio, Spyder\n",
    "- Execution Environment : Apache Spark, Apache Flink\n",
    "- Fully Integrated Environment : KNIME, Orange \n",
    "\n",
    "\n",
    "# 2.3 Package, API \n",
    "\n",
    "### Package \n",
    "\n",
    "- Framework \n",
    "    - Pandas : Offers data structures and tools for effective data clearning, manipulation, and analysis \n",
    "    - Numpy : Based on arrays, enabling us to apply mathmetical functions to these arrays\n",
    "- Visualization : Matplotlib, Seaborn, Plotly \n",
    "- Machine Learning : Scikit-Learn, Keras, Tensorflow, Pytorch \n",
    "\n",
    "### API \n",
    "\n",
    "API : Application Programming Interface, which can talk with other software\n",
    "\n",
    "\n",
    "# 2.4 Jupyter Notebook Source \n",
    "\n",
    "- Best Source : https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks\n",
    "- EDA : https://nbviewer.jupyter.org/github/Tanu-N-Prabhu/Python/blob/master/Exploratory_data_Analysis.ipynb\n",
    "- Data Integration : https://towardsdatascience.com/data-cleaning-with-python-using-pandas-library-c6f4a68ea8eb\n",
    "- Clustering : https://nbviewer.jupyter.org/github/temporaer/tutorial_ml_gkbionics/blob/master/2%20-%20KMeans.ipynb\n",
    "\n",
    "# 2.5 Github \n",
    "\n",
    "```Git\n",
    "/* SSH key generate */ \n",
    "cat ~/.ssh/id_rsa.pub | clip\n",
    "cat ~/.ssh/id_rsa.pub\n",
    "\n",
    "cd\n",
    "cd Downloads\n",
    "\n",
    "git clone git@github.com:EDED-Hiscalifh/repository.git \n",
    "\n",
    "/* View content of the repository */\n",
    "type README.md \n",
    "\n",
    "/* Open README.md */\n",
    "notepad README.md\n",
    "notepad test.txt \n",
    "\n",
    "git add test.txt \n",
    "git status \n",
    "git commit -m \"text for commit\" \n",
    "git push \n",
    "\n",
    "/* Branching and Merging */ \n",
    "\n",
    "git pull \n",
    "\n",
    "git branch new_branch /* Add a branch in master branch */ \n",
    "git checkout new_branch /* Switch to new_branch */ \n",
    "echo \"content\" >> filename.txt \n",
    "\n",
    "git push --set-upstream origin new_branch /* Add the file and push the file to new_branch */ \n",
    "\n",
    "git checkout main /* Switch the master branch */ \n",
    "git merge new_branch \n",
    "\n",
    "git push \n",
    "\n",
    "/* Fork and Pull */ \n",
    "\n",
    "git clone git@github.com:EDED-Hiscalifh/fork.git\n",
    "\n",
    "git add . \n",
    "git commit -m \"Made changes in README.md file\"\n",
    "\n",
    "git push\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc553be",
   "metadata": {},
   "source": [
    "# 3. Methodology \n",
    "\n",
    "## 3.1 What is Methodology ? \n",
    "\n",
    "A system of methods used in a particular area of study or activity. \n",
    "\n",
    "- From problem to approach : \n",
    "    - What is the problem that we are trying to solve? \n",
    "    - How can we use data to answer the question? \n",
    "- Working with the data : \n",
    "    - What data do we need to answer the question? \n",
    "    - Whrere is the data coming from (identify all sources) and how will we get it? \n",
    "    - Is the data that we collected representative of the problem to be solved? \n",
    "    - What additional work is required to manipulate and work with data? \n",
    "- Deriving the answer : \n",
    "    - In what way can the data be visualized to get the answer that is required? \n",
    "    - Does the model used really answer the initial question or does it need to be adjusted? \n",
    "    - Can we put the model into practice? \n",
    "    - Can we get construcive feedback into answering the question? \n",
    "    \n",
    "## 3.2 Methodology workflow \n",
    "\n",
    "- Business understanding : Business undefstanding is checking the problem or the goal of particular business wer are working. In this section, we need to find the problem and specific goal of stackholder or board of directors. \n",
    "- Analytic understanding : In this section, we need to select which model is the best way to solve the problem in Business understanding. \n",
    "- Data requirements : In this section, we identifies the necessary data content, formats and souces for initial data. \n",
    "- Data collection : After identifying data requirements, we now collect data. (extracting data + When I usually do 'Importing data' is the stage of data collection.)\n",
    "\n",
    "## 3.3 CRISP-DM \n",
    "\n",
    "- Data understanding : https://www.dummies.com/programming/big-data/phase-2-of-the-crisp-dm-process-model-data-understanding/. It can be same as Basic EDA what i usually use in analyzing.\n",
    "- Data preparation : Transforming data for model(drop duplicated, invalid values, ...). Feature engineering is the process of using domain knowledge of the data to create feature that make the machine learning algorithm work. \n",
    "- Modeling : Focus on developing models that are either descriptive or predictive using machine learning.\n",
    "- Model Evaluation : Allows the quality of the model to be assessed and give opportunity to see if it meets the initial request.\n",
    "- Deployment : After fishish model evaluation, we now solve the problem.\n",
    "- Feedback : If there are problem when we deploy using model, we feedback anytime and refine model talking with board."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc01837",
   "metadata": {},
   "source": [
    "# 4. Python \n",
    "\n",
    "## 4.1 Types \n",
    "\n",
    "There are some type when we use in programming\n",
    "\n",
    "- int : single number without point\n",
    "- float : including int, usually with point 1.0, 2.043\n",
    "- string : 'A' or words\n",
    "- boolean : meaning True(1), False(0)\n",
    "\n",
    "There are some function when we want to change types. Becareful when we use int(), because it drop number behind point.\n",
    "\n",
    "```Python\n",
    "float() \n",
    "int()\n",
    "bool()\n",
    "str()\n",
    "```\n",
    "\n",
    "## 4.2 Expression \n",
    "\n",
    "```Python\n",
    "+ - * \n",
    "/ #divide with float \n",
    "// #divide with single number\n",
    "```\n",
    "\n",
    "## 4.3 Variable \n",
    "\n",
    "We assign what we want to remember or to use to the variable. \n",
    "\n",
    "```Python\n",
    "my_variable = 1\n",
    "my_variable = 1/5 #past of values are disappeared\n",
    "```\n",
    "\n",
    "## 4.4 String Operation\n",
    "\n",
    "```Python\n",
    "#indexing of string\n",
    "Name = 'Jeong Seok Gyu'\n",
    "Name[0] -> J\n",
    "Name[-1] -> u\n",
    "Name[::2] #select every even index J,o,g,S,o, ,y\n",
    "Name[0:5:2] #select every even index in 0:5\n",
    "\n",
    "len() \n",
    "Name + 'is best'\n",
    "3*name \n",
    "\\n #\n",
    "\\t #tab\n",
    ".upper()\n",
    ".lower()\n",
    ".replace('want to change', 'want to be change')\n",
    ".find()\n",
    "```\n",
    "\n",
    "## 4.5 Tuple \n",
    "\n",
    "Tuples are an ordered sequence written as comma-separted elements within parenthese. when we want to add some tuple to another tuple, then we add them within parenthese.\n",
    "\n",
    "```Python\n",
    "tuple = (0,1,2,3,4,5)\n",
    "tuple[0]\n",
    "tuple[0:4]\n",
    "\n",
    "tuples[0] = 4 <- error!\n",
    "\n",
    "#Nesting indexing\n",
    "tuple1 = (1,2,(1,2,3),(1,2,3,4),5)\n",
    "tuple1[2][1] <- 2\n",
    "```\n",
    "\n",
    "Same as str, indexing of tuples are same. But assigning of tuples can't be done. Because main property of tuples is 'Immutable'.\n",
    "\n",
    "\n",
    "## 4.6 List \n",
    "\n",
    "List can involve many structure such as str, float, tuple, even a tuple. Indexing of list is same as tuple.\n",
    "\n",
    "Unlikely with tuple, List is mutable so that we can change them.\n",
    "\n",
    "```Python\n",
    ".extend()\n",
    ".append()\n",
    "\n",
    "for examples, \n",
    "l = [1,2,3,4]\n",
    "l.extend([1,2,3])\n",
    "l -> [1,2,3,4,1,2,3]\n",
    "l.append([1,2,3])\n",
    "l -> [1,2,3,4,[1,2,3]]\n",
    "\n",
    "\n",
    "del() #delete index of list\n",
    "split() #split in (seperator)\n",
    "```\n",
    "\n",
    "## 4.7 Dictionary\n",
    "\n",
    "In list and tuple, we index by calling number index, but in dictionary, we index by calling key which is not type of int. \n",
    "\n",
    "```Python\n",
    "Dict = {'one' : 'one', 'two' : (1,2,3,4)}\n",
    "\n",
    "Dict['one'] -> one\n",
    "Dict['two'][0] -> 1\n",
    "\n",
    ".keys()\n",
    ".values() #when we want to know whole keys and values\n",
    "```\n",
    "\n",
    "## 4.8 Sets \n",
    "\n",
    "```Python\n",
    "set = {'one', 'one', 'two', 'two', 'three', 'three'}\n",
    "set => {'one' ,'two', 'three'}\n",
    "\n",
    "list = ['one', 'two', 'three']\n",
    "set(list)\n",
    "\n",
    ".add() \n",
    ".remove()\n",
    ".union() #outerjoin sets\n",
    ".difference() \n",
    ".intersection()\n",
    ".issubset() #check True of subset\n",
    "```\n",
    "\n",
    "## 4.9 Condition\n",
    "\n",
    "Condition means result of operation in two situation, True and False. And can apply to all types.\n",
    "\n",
    "```Python\n",
    "i = 8\n",
    "i > 5 -> False\n",
    "i > 2 -> True\n",
    "i >= 8 -> True\n",
    "```\n",
    "\n",
    "Branching is used in if statement. If condition is true, then code in if statement works, if not it doesn't work. 'else' condition works with if statement when return of if statement is False. 'elif' statement is contraction version of 'else if' so that it can be used between if statement and else statement. \n",
    "\n",
    "```Python\n",
    "if (your_age>20) : \n",
    "     print('you can drink beer')\n",
    "elif(your_age<10) :\n",
    "     print('you can't enter')\n",
    "else : \n",
    "     print('you can't drink beer')\n",
    "```\n",
    "\n",
    "If statement can be with logical operation 'OR', 'AND'. \n",
    "\n",
    "```Python\n",
    "if (car_year<10)or(car_year>20) : \n",
    "     print('Not good for sold')\n",
    "else : \n",
    "     print('Good for sold')\n",
    "```\n",
    "\n",
    "## 4.10 Loop\n",
    "\n",
    "```Python\n",
    "range(N) -> [0,...,N-1]\n",
    "range(10,15) ->[10,11,12,13,14]\n",
    "```\n",
    "\n",
    "for loops statement repeat index of created by range() indexing value of list.\n",
    "\n",
    "```Python\n",
    "loop = [1,2,3,4]\n",
    "\n",
    "for i in range(0,5) :\n",
    "     loop[i] = 'changed'\n",
    "-> loop = ['changed', 'changed', 'changed', 'changed']\n",
    "\n",
    "for i, value in enumerate(loop) : \n",
    "     print(i, value)\n",
    "-> 0, 'changed'; 1, 'changed'; 2, 'changed'; 3, 'changed'\n",
    "\n",
    "#enumerate return index and value of object in enumerate()\n",
    "```\n",
    "\n",
    "while statement works untill there isn't any statement that is true. \n",
    "\n",
    "```Python\n",
    "list = [1,2,3,4,1,2,3]\n",
    "New_list = []\n",
    "i = 0\n",
    "\n",
    "while(list[i] == 1) :\n",
    "     New_list.append(list[i])\n",
    "     i = i+1\n",
    "```\n",
    "\n",
    "## 4.11 Function\n",
    "\n",
    "Functions take some input then produce some output or change. Once we complete long process into function, we can use function when we want. There are function in two type. One is 'built-in-function', the other is 'own function'.\n",
    "\n",
    "```Python\n",
    "def add(a) : \n",
    "    b = a+1 \n",
    "    return b\n",
    "\n",
    "#multiple parameter(a,b) :\n",
    "def add(a,b) :\n",
    "    c = a+b\n",
    "    return c\n",
    "\n",
    "#collecting argument\n",
    "def MyNames(*names) :\n",
    "    for name in names :\n",
    "         print(name)\n",
    "MyNames('Hong', 'Gill', 'Dong')\n",
    "```\n",
    "\n",
    "## 4.12 Exception\n",
    "\n",
    "It is important to know what error has been occured. When we implement code in try :, if there are some errors in code, then except : code will implement. If there are no errors in code, then else : code will implement.\n",
    "\n",
    "```Python\n",
    "try :\n",
    "   ...\n",
    "except ['error']:\n",
    "    ...\n",
    "except ['error']:\n",
    "    ...\n",
    "else :\n",
    "```\n",
    "\n",
    "## 4.13 Objects and Class \n",
    "\n",
    "Every object has a type, an internal data representation, a set of procedures for interacting with the object.\n",
    "\n",
    "- Class : blueprint for creating Objects\n",
    "- Objects : Instance of Class \n",
    "\n",
    "```Python\n",
    "class Circle(object) : -> define our class\n",
    "    def __init__(self, radius, color) : \n",
    "        self.radius = radius ;\n",
    "        self.color = color ;\n",
    "# Data attributes used to initialize each instance of the class\n",
    "```\n",
    "\n",
    "## 4.14 Read Files \n",
    "\n",
    "```Python\n",
    "#open\n",
    "File1 = open('Path' + 'file name', 'w/r/a')\n",
    "with open('Path' + 'file name', 'w/r/a') as File1 :\n",
    "    ...\n",
    "\n",
    ".readlines() -> read full line in list\n",
    ".readline() -> read only one line\n",
    "\n",
    "#after open\n",
    ".name -> check file name\n",
    ".mode -> check file reading mode\n",
    ".close() # We don't have to use file.close() when we use with comprehensions \n",
    "\n",
    "#writing File\n",
    "File1 = open('Path' + 'file name', 'w')\n",
    "File1.write('blabla')\n",
    "\n",
    "with open('Path' + 'file_name', 'w') as File1 :\n",
    "    File1.write('blabla')\n",
    "\n",
    "#adding File\n",
    "File1 = open('Path' + 'file name', 'a')\n",
    "with open('Path' + 'file name', 'a') as File1 :\n",
    "```\n",
    "\n",
    "## 4.15 Open \n",
    "\n",
    "```Python\n",
    "import pandas\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Path' + 'file name')\n",
    "df = pd.read_excel('Path' + 'file name')\n",
    "\n",
    "df.to_csv('file name')\n",
    "```\n",
    "\n",
    "## 4.16 Numpy \n",
    "\n",
    "```Python\n",
    "import numpy as np\n",
    "\n",
    "#1-D array\n",
    "a = np.array([0,1,2,3,4,5])\n",
    "\n",
    "#checking \n",
    "a.size -> 5\n",
    "a.ndim -> 1\n",
    "a.shape -> (5,1)\n",
    "\n",
    "#vector addition and substraction\n",
    "z = u + v\n",
    "z = u - v\n",
    "z = 2 * y\n",
    "np.dot(u,v)\n",
    "\n",
    "#Universal Functions\n",
    ".mean()\n",
    ".max()\n",
    "np.pi\n",
    "np.sin(x)\n",
    "np.linspace(-2,2,num = 5)\n",
    "#2-D array\n",
    "a = [[1,2,3], [4,5,6], [7,8,9]]\n",
    "A = np.array(a)\n",
    "\n",
    "#checking \n",
    "a.size -> 9\n",
    "a.ndim -> 2\n",
    "a.shape -> (3,3)\n",
    "\n",
    "#indexing\n",
    "A[i][j] -> i : row, j : column\n",
    "A[a:b,c:d]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac32af7f",
   "metadata": {},
   "source": [
    "# 5. SQL \n",
    "\n",
    "## 5.1 What is SQL ? \n",
    "\n",
    "**SQL(Structured Query Language)** is a language used for relational databases to query or get data out of a database. Relational databases mean table data form such a dataframe. \n",
    "\n",
    "Data is a collection of facts in the form of words, numbers, or even pictures. Data is one of the most critical assets of any business. It is used and collected practically everywhere. \n",
    "\n",
    "Databases is a repository of data. It is a program that stores data and also provides the functionality for adding, modifying, and querying that data. A set of software toosl for the data in the database is called a database management system or DBMS for short. The terms databases, database server, database system, data server, and data management systeems are often interchangeably. \n",
    "\n",
    "## 5.2 DML \n",
    "\n",
    "### SELECT \n",
    "\n",
    "It seems like df.loc or df.iloc in pandas library. \n",
    "\n",
    "```SQL \n",
    "SELECT COLUMN1, COLUMN2, ... \n",
    "  FROM TABLE1 ;\n",
    "\n",
    "SELECT COLUMN1, COLUMN2, ... \n",
    "  FROM TABLE1 \n",
    " WHERE ID = 'CA'; \n",
    "```\n",
    "\n",
    "### COUNT, DISTINCT, LIMIT \n",
    "\n",
    "- COUNT() : Built-in database function that retrives the number of rows that match the query criteria. \n",
    "- DISTINCT() : Used to remove duplicated values from a result set. \n",
    "- LIMIT : Used for restricting the number of rows retrieved from the database. \n",
    "\n",
    "```SQL\n",
    "SELECT COUNT(*) \n",
    "  FROM TABLE ;\n",
    "\n",
    "SELECT COUNT(COLUMN) \n",
    "  FROM TABLE \n",
    " WHERE ID = 'CA';\n",
    "\n",
    "SELECT DISTINCT COLUMN \n",
    "  FROM TABLE; \n",
    "\n",
    "SELECT COUNT(DISTINCT COLUMN) \n",
    "  FROM TABLE \n",
    " WHERE ID = 'CA';\n",
    "\n",
    "SELECT * \n",
    "  FROM TABLE \n",
    " LIMIT n1 \n",
    "OFFSET n2;\n",
    "```\n",
    "\n",
    "### INSERT, UPDATE, DELETE\n",
    "\n",
    "- INSERT : Used to add new rows to a table. We can also add multiple rows.\n",
    "- UPDATE : After a table created, the table can altered with UPDATE claus.\n",
    "- DELETE : Delete rows in specific condition. \n",
    "\n",
    "```SQL \n",
    "INSERT INTO table_name (column1, column2, ... )\n",
    "VALUES (value1, value2, ... );\n",
    "\n",
    "UPDATE table_name\n",
    "SET column1 = value1, \n",
    "    column2 = value2, ...\n",
    "WHERE condition;\n",
    "\n",
    "DELETE FROM table_name\n",
    " WHERE condition;\n",
    "```\n",
    "\n",
    "## 5.2 Relational Databases \n",
    "\n",
    "RDBMS is most used data model. It is stored in a tables and allowed for data independence. ER Database model have three features below : \n",
    "\n",
    "- Entity : Independent objects which have attributes. \n",
    "- Attributes : Properties of entity and map to columns in table.\n",
    "- Primary Key : Uniquely identifies a specific row in a table(entity). \n",
    "\n",
    "There are two types of commands. \n",
    "\n",
    "- DDL(Data Definition Language) : Define, Change, Drop table (CREATE, ALTER, DROP, TRUNCATE)\n",
    "- DML(Data Manipulation Language) : Read, Modifying data for CRUD operation (INSERT, UPDATE, DELETE, SELECCT) \n",
    "\n",
    "## 5.3 DDL \n",
    "\n",
    "### CREATE\n",
    "\n",
    "```SQL\n",
    "CREATE TABLE table_name\n",
    "     (\n",
    "     column_name1 datatype optional_parameters, \n",
    "     column_name2 datatype,\n",
    "     column_name3 datatyoe,\n",
    "     ...\n",
    "     )\n",
    "\n",
    "CREATE TABLE author (\n",
    "     author_id CHAR(2) PRIMARY KEY NOT NULL, \n",
    "     lastname VARCHAR(15) NOT NULL,\n",
    "     firstname VARCHAR(15) NOT NULL,\n",
    "     email VARCHAR(40),\n",
    "     city VARCHAR(15),\n",
    "     )\n",
    "```\n",
    "\n",
    "### ALTER \n",
    "\n",
    "```SQL\n",
    "ALTER TABLE table_name\n",
    "  ADD COLUMN column_name datatype;\n",
    "\n",
    "ALTER COLUMN column_name \n",
    "  SET DATA TYPE datatype;\n",
    " DROP COLUMN column_name\n",
    "```\n",
    "\n",
    "### DROP \n",
    "\n",
    "```SQL\n",
    "DROP TABLE table_name;\n",
    "```\n",
    "\n",
    "### TRUNCATE \n",
    "\n",
    "```\n",
    "TRUNCATE TABLE table_name\n",
    "     IMMEDIATE; \n",
    "```\n",
    "\n",
    "## 5.4 SELECT \n",
    "\n",
    "### SELECT \n",
    "\n",
    "```SQL\n",
    "/* Basic form using WHERE */ \n",
    "SELECT COLUMN1, COLUMN2, ... \n",
    "  FROM TABLE1 ;\n",
    "\n",
    "SELECT COLUMN1, COLUMN2, ... \n",
    "  FROM TABLE1 \n",
    " WHERE ID = 'CA';\n",
    " \n",
    "/* Extract records matching pattern */ \n",
    "SELECT COLUMN1, COLUMN2, ... \n",
    "  FROM TABLE1 \n",
    " WHERE COLUMN1 LIKE (predicate)\n",
    "\n",
    "SELECT COLUMN1 \n",
    "  FROM table \n",
    " WHERE firstname LIKE R%\n",
    " \n",
    "/* Use between rather than using >= and <= */ \n",
    "SELECT title, page \n",
    "  FROM BOOK \n",
    " WHERE pages >= 290 and <= 300\n",
    "\n",
    "SELECT title, page \n",
    "  FROM BOOK \n",
    " WHERE pages betwen 290 and 300\n",
    "\n",
    "/* Use in rather than using multiple or */ \n",
    "SELECT firstname, lastname, country \n",
    "  FROM AUTHOR \n",
    " WHERE country = 'AU' OR country = 'BR'\n",
    "\n",
    "SELECT firstname, lastname, country \n",
    "  FROM AUTHOR \n",
    " WHERE coutnry IN ('AU', 'BR')\n",
    "```\n",
    "\n",
    "### Sorting \n",
    "\n",
    "We can also get result in form we want to see. The default setting of ORDER BY is ascending. If we want to order in decending order, then we add DESC at last. \n",
    "\n",
    "```SQL\n",
    "SELECT COLUMN1 \n",
    "  FROM TABLE \n",
    " ORDER BY column(or indicated index number)\n",
    "\n",
    "SELECT COLUMN1 \n",
    "  FROM TABLE \n",
    " ORDER BY column(or indicated index number) DESC\n",
    "```\n",
    "\n",
    "### Grouping \n",
    "\n",
    "We drop duplicated data by using DISTINCT function. If we want to see how many duplicated data by column, then we use GORUP BY clause.\n",
    "\n",
    "```SQL\n",
    "SELECT COLUMM1, COUNT(COLUMN1) \n",
    "  FROM TABLE GROUP BY COLUMN1\n",
    "\n",
    "SELECT COLUMN1, COUNT(COLUMN1) As column \n",
    "  FROM TABLE \n",
    " GROUP BY COLUMN1\n",
    "```\n",
    "\n",
    "If we use just GROUP BY, column name of COUNT() will be just 2. We can use \"AS\" to rename those column name. \n",
    "\n",
    "HAVING clause is used in GROUP BY same as WHERE. Unlikely with WEHRE, WHERE is used for whole table, HAVING is used in GROUP BY. \n",
    "\n",
    "```SQL \n",
    "SELECT COLUMN1, COUNT(COLUMN1) \n",
    "  FROM TABLE AS column \n",
    " GROUP BY COLUMN1 HAVING (prediciate)\n",
    "```\n",
    "\n",
    "### Conclusion \n",
    "\n",
    "```SQL\n",
    "Select column1, count(column1) as new_colname, D.disticnt(column2), avg(column1), ... \n",
    "  FROM ~\n",
    "\n",
    "/* if we want count of column as new_colname we use count(), 'as' */ \n",
    "/* we can retrieve from other table col as D.colname */ \n",
    "\n",
    "\n",
    "FROM TABLE AS T, TABLE2 AS T2\n",
    "\n",
    "/* we can retrieve table's data by using as */ \n",
    "\n",
    "/* After FROM */  \n",
    "WHERE (predicate);\n",
    "WHERE column LIKE '(predicate)%';\n",
    "WHERE column (predicate) AND/OR (predicate);\n",
    "WHERE column BETWEEN n1 and n2;\n",
    "WHERE column IN (set);\n",
    "\n",
    "ORDER BY column;\n",
    "ORDER BY column DESC;\n",
    "WHERE ~ ORDER BY column DESC;\n",
    "\n",
    "GROUP BY column;\n",
    "GROUP BY column ORDER BY column;\n",
    "GROUP BY column HAVING (predicate) ORDER BY column;\n",
    "```\n",
    "\n",
    "## 5.5 Built-in Function \n",
    "\n",
    "### Built-in function\n",
    "\n",
    "```SQL\n",
    "SUM()\n",
    "MIN()\n",
    "MAX()\n",
    "AVG()\n",
    "\n",
    "/* Scalar, String function */ \n",
    "ROUND()\n",
    "LENGTH()\n",
    "UCASE() /* return upper case from string */\n",
    "LCASE() /* return lower case from string */\n",
    "\n",
    "/* all built in function can be used with WHERE */\n",
    "SELECT SUM(column1) \n",
    "  FROM TABLE \n",
    " WHERE (predicate) ;\n",
    "\n",
    "/* Data, Time function */ \n",
    "DAY()\n",
    "Datecolum + 3 Days\n",
    "CURRENT_DATE\n",
    "CURRENT_TIME\n",
    "/* it also can be used with WHERE */ \n",
    "```\n",
    "\n",
    "### Sub Queries \n",
    "\n",
    "We use sub-queries becuase built-in function cannot evaluate function in the WHERE clause. \n",
    "\n",
    "```SQL \n",
    "SELECT * \n",
    "  FROM TABLE \n",
    " WHERE column > AVG(column); /* error! */ \n",
    " \n",
    "SELECT * \n",
    "  FROM TABLE \n",
    " WHERE column > (SELECT AVG(column) \n",
    "                   FROM TABLE);\n",
    "```\n",
    "\n",
    "Sub-queries used in front of FROM, after FROM when error occurs. \n",
    "\n",
    "```SQL \n",
    "SELECT cloumn1, column2, AVG(column1) \n",
    " FROM TABLE; /* error! */ \n",
    " \n",
    "SELECT column1, column2, (SELECT AVG(column1) \n",
    "                            FROM TABLE) AS AVG_column1\n",
    "  FROM TABLE; \n",
    "\n",
    "SELECT * \n",
    "  FROM (SELECT column1, column2, column3 \n",
    "          FROM TABLE) AS NEW_TABLE;\n",
    "```\n",
    "\n",
    "### Multiple Tables \n",
    "\n",
    "```SQL\n",
    "/* Way1 */ \n",
    "SELECT * \n",
    "  FROM TABLE \n",
    " WHERE column IN (SELECT column \n",
    "                    FROM TABLE1);\n",
    "\n",
    "SELECT * \n",
    "  FROM TABLE \n",
    " WHERE column IN (SELECT column \n",
    "                    FROM TABLE1 \n",
    "                   WHERE (predicate));\n",
    "\n",
    "/* Way2 */ \n",
    "SELECT * \n",
    "  FROM TABLE1, TABLE2;\n",
    "  \n",
    "SELECT * FROM TABLE1, TABLE2 \n",
    " WHERE TABLE1.column = TABLE2.colum1;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bc1bc5",
   "metadata": {},
   "source": [
    "# 6. Database on Python\n",
    "\n",
    "## 6.1 Code using DB-API \n",
    "\n",
    "We can access database using python library DB-API. \n",
    "\n",
    "- from dbmodule import connect \n",
    "- Create connection object : Connection = connection('dbname', 'username', 'pswd') \n",
    "- Create a cursor object : cursor = connection.cursor() \n",
    "- Run queries : cursor.execute(query) \n",
    "\n",
    "## 6.2 Connecting to DB \n",
    "\n",
    "```Python\n",
    "import ibm_db\n",
    "\n",
    "#Replace the placeholder values with your actual Db2 hostname, username, and password:\n",
    "dsn_hostname = \"YourDb2Hostname\" # e.g.: \"dashdb-txn-sbox-yp-dal09-04.services.dal.bluemix.net\"\n",
    "dsn_uid = \"YourDb2Username\"        # e.g. \"abc12345\"\n",
    "dsn_pwd = \"YoueDb2Password\"      # e.g. \"7dBZ3wWt9XN6do0J\"\n",
    "\n",
    "dsn_driver = \"{IBM DB2 ODBC DRIVER}\"\n",
    "dsn_database = \"BLUDB\"            # e.g. \"BLUDB\"\n",
    "dsn_port = \"50000\"                # e.g. \"50000\" \n",
    "dsn_protocol = \"TCPIP\"            # i.e. \"TCPIP\"\n",
    "\n",
    "#Create DB2 database connection\n",
    "dsn = (\n",
    "    \"DRIVER={0};\"\n",
    "    \"DATABASE={1};\"\n",
    "    \"HOSTNAME={2};\"\n",
    "    \"PORT={3};\"\n",
    "    \"PROTOCOL={4};\"\n",
    "    \"UID={5};\"\n",
    "    \"PWD={6};\").format(dsn_driver, dsn_database, dsn_hostname, dsn_port, dsn_protocol, dsn_uid, dsn_pwd)\n",
    "\n",
    "try:\n",
    "    conn = ibm_db.connect(dsn, \"\", \"\")\n",
    "    print (\"Connected to database: \", dsn_database, \"as user: \", dsn_uid, \"on host: \", dsn_hostname)\n",
    "\n",
    "except:\n",
    "    print (\"Unable to connect: \", ibm_db.conn_errormsg() )\n",
    "```\n",
    "\n",
    "## 6.3 Manipulate DB using Python \n",
    "\n",
    "```Python\n",
    "#Create table\n",
    "createQuery = 'sql for CREATE TABLE'\n",
    "creatstmt = ibm_db.exec_immediate(conn, createQuery)\n",
    "\n",
    "#Insert table\n",
    "insertQuery = 'sql for INSERT INTO TABLE'\n",
    "insertstmt = ibm_db.exec_immediate(conn, insertQuery)\n",
    "\n",
    "#Visual table\n",
    "sql = 'SELECT * FROM TABLE'\n",
    "selectstmt = ibm_db.exec_immediate(conn, sql)\n",
    "ibm_db.fetch_both(selectstmt)\n",
    "\n",
    "#retreive data into pandas \n",
    "import pandas\n",
    "import ibm_db_dbi\n",
    "\n",
    "pconn = ibm_db_dbi.Connection(conn)\n",
    "selectQuery = \"select * from INSTRUCTOR\"\n",
    "pdf = pandas.read_sql(selectQuery, pconn)\n",
    "```\n",
    "\n",
    "## 6.4 %Magic\n",
    "\n",
    "We can use sql without setting variable. %magic is add-on function in IPython system, which consisted with %, %%.\n",
    "\n",
    "- % : execute code in one line\n",
    "- %% : execute code in all line \n",
    "\n",
    "```Python\n",
    "%load_ext sql\n",
    "\n",
    "# Enter the connection string for your Db2 on Cloud database instance below\n",
    "# %sql ibm_db_sa://my-username:my-password@my-hostname:my-port/my-db-name\n",
    "\n",
    "# type in your query to retrieve list of all tables in the database for your db2 schema (username)\n",
    "%sql select TABSCHEMA, TABNAME, CREATE_TIME from SYSCAT.TABLES \\\n",
    "      where TABSCHEMA not in ('SYSIBM', 'SYSCAT', 'SYSSTAT', 'SYSIBMADM', 'SYSTOOLS', 'SYSPUBLIC')\n",
    "\n",
    "# type in your query to retrieve the number of columns in the SCHOOLS table\n",
    "%sql select count(*) from SYSCAT.COLUMNS where TABNAME = 'SCHOOLS'\n",
    "\n",
    "# type in your query to retrieve all column names in the SCHOOLS table along with their datatypes and length\n",
    "%sql select distinct(NAME), COLTYPE, LENGTH from SYSIBM.SYSCOLUMNS where TBNAME = 'SCHOOLS'\n",
    "\n",
    "\n",
    "%sql select Elementray,_Middle,_or_High_School from SCHOOLS \n",
    "%sql select SAFETY_SCORE from SCHOOLS order by SAFETY_SCORE DESC LIMIT 100\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d28c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "352px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
