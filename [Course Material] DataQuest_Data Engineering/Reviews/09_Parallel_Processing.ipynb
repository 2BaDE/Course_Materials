{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b8e5aa",
   "metadata": {},
   "source": [
    "# Introductions to Parallel Processing \n",
    "\n",
    "## What is Parallel Processing \n",
    "\n",
    "In order to process a large dataset in a situation where available memory was limited, data had to be processed by splitting it into **chunks**. **Parallel Processing** increases the speed of work by simultaneously processing chunks. \n",
    "\n",
    "A **Central Processing Unit(CPU)** is a hardware that processes computer operations. The old CPU was able to perform only one task in a single core, but the current CPU is now capable of parallel processing using multi-core processing. \n",
    "\n",
    "Python's multiprocessing module provides a package that enables parallel processing. \n",
    "\n",
    "```Python\n",
    "import multiprocessing \n",
    "```\n",
    "\n",
    "## Process \n",
    "\n",
    "**Process.start()** \n",
    "\n",
    "The multiprocessing.Process() method creates a process for parallel processing by creating a Process object. The target parameter of the Process() method enters the process (functions) to be processed. The generated Process object is executed through the Process.start() method. \n",
    "\n",
    "```Python\n",
    "import time\n",
    "def wait():\n",
    "    time.sleep(0.5)\n",
    "    print(\"Done waiting\")\n",
    "\n",
    "process = multiprocessing.Process(target=wait)\n",
    "\n",
    "# Add code here\n",
    "process.start()\n",
    "print(\"Finished\")\n",
    "process.join()\n",
    "```\n",
    "\n",
    "**Process.join()**\n",
    "\n",
    "As a result of the execution of the above program, \"Finished\" is the first output and \"Done waiting\" is executed next. \n",
    "\n",
    "PythonIDE proceeds the code in the order of exposure. However, after executing Process.start(), the wait() function executed in parallel is delayed by time.sleep(), so print(\"Finished\") is executed first. \n",
    "\n",
    "Process.join() is used to terminate an ongoing process to execute another waiting process. Therefore, the code for producing the desired result is as follows: \n",
    "\n",
    "```Python\n",
    "import time\n",
    "def wait():\n",
    "    time.sleep(0.5)\n",
    "    print(\"Done waiting\")\n",
    "\n",
    "process = multiprocessing.Process(target=wait)\n",
    "\n",
    "# Add code below\n",
    "\n",
    "process.start()\n",
    "process.join()\n",
    "print(\"Finished\")\n",
    "```\n",
    "\n",
    "## Execution time of Parallele Processing \n",
    "\n",
    "In the workflow of multiprocessing, the main program waits until all processes are finished an synthesizes each result to output the entire result. However, since each process is executed in parallel, the execution time is divided by the number of process.\n",
    "\n",
    "\n",
    "1. Divide each operation by chunk.\n",
    "2. Perform a process for each chunk.\n",
    "3. Wait until all processes are finished.\n",
    "4. Summarize the results. \n",
    "\n",
    "```Python\n",
    "import time\n",
    "def wait():\n",
    "    time.sleep(0.5)\n",
    "    print(\"Done waiting\")\n",
    "\n",
    "# Add code below\n",
    "start = time.time()\n",
    "wait()\n",
    "end = time.time()\n",
    "elapsed1 = end - start\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "p1 = multiprocessing.Process(target = wait)\n",
    "p2 = multiprocessing.Process(target = wait)\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "p1.join()\n",
    "p2.join()\n",
    "\n",
    "end = time.time()\n",
    "elapsed2 = end - start\n",
    "```\n",
    "\n",
    "As a result of the implementation, there is little difference between elapsed1 and elapsed2. \n",
    "\n",
    "## Parallel Processing with arguments \n",
    "\n",
    "어떤 프로세스에 구성된 함수에 입력값이 필요한 경우가 있는 경우, Process() 메소드는 target parameter외에 args parameter를 통해 해당 함수의 arguments를 입력받을 수 있다. 또한 입력받은 arguments는 iterable하기 때문에 객체의 형태를 그대로 대입할 수 있다.\n",
    "\n",
    "```Python\n",
    "def sum3(x, y, z):\n",
    "    print(x + y + z)\n",
    "\n",
    "def list_average(values):\n",
    "    print(sum(values) / len(values))\n",
    "\n",
    "# Add code below\n",
    "\n",
    "sum3_process = multiprocessing.Process(target = sum3, args = [3, 2, 5])\n",
    "list_average_process = multiprocessing.Process(target = list_average, args = [[1, 2, 3, 4, 5]])\n",
    "\n",
    "sum3_process.start()\n",
    "list_average_process.start()\n",
    "sum3_process.join()\n",
    "list_average_process.join()\n",
    "```\n",
    "\n",
    "## Shared memory \n",
    "\n",
    "앞선 방식의 프로세스는 함수의 값을 받을 수 없다. 함수는 독립적인 프로세스에서 실행되고 있기 때문에 각각의 메모리에  존재하며 다른 프로세스와 값을 공유하지 못한다. **Shared memory** 방식은 값을 return하는 대신에 결과값을 shared memory 위치에 저장하고 있어 값을 저장할 수 있다. \n",
    "\n",
    "multiprocessing.Value 객체는 함수를 정의할 때 함수의 argument 형태로 작성되어 값을 접근하고 사용할 수 있도록 한다. 해당 값을 access 하는 방식은 Value.value 속성을 통해 가능하다. 프로세스를 생성하기 이전에 Value 또한 정의되어야 하는데, Value() 메소드 내부에 데이터 타입을 정의할 필요가 있다. 이후에 생성된 객체를 args prameter에 추가적으로 입력하면 된다. \n",
    "\n",
    "```Python\n",
    "def sum3(x, y, z, shared_value) : \n",
    "    shared_value.value = x + y + z \n",
    "    \n",
    "\n",
    "float_value = multiprocessing.Value(\"f\")\n",
    "process = multiprocessing.Process(target = sum3, args = [5, 7, 4, float_value])\n",
    "process.start()\n",
    "process.end()\n",
    "print(float_value) \n",
    "```\n",
    "\n",
    "## Cautions of sharing value \n",
    "\n",
    "multiprocessing.Value는 single value만 저장할 수 있다. 따라서 프로세스 사이에서 shared memory를 사용할 때 동시에 값을 업데이트 하지 않도록 주의해야 한다. 예를들어 1 ~ 10000까지의 수를 더하는 프로세스를 1 ~ 4999, 5000 ~ 10000까지 계산하는 두 개의 병렬 프로세스로 분할하여 처리한다고 할때 하나의 shared value만 사용하게 되면 각각의 프로세스에서 처리된 값이 서로 shared memory에 업데이트 되는 문제가 발생한다.\n",
    "\n",
    "```Python\n",
    "def sum_values(first, last, shared_value):\n",
    "    for i in range(first, last):\n",
    "        shared_value.value += i\n",
    "\n",
    "def sum_with_two_processes():\n",
    "    N = 10000\n",
    "\n",
    "    shared_value = multiprocessing.Value(\"i\")\n",
    "    process1 = multiprocessing.Process(target=sum_values, args=(1, N // 2, shared_value))\n",
    "    process2 = multiprocessing.Process(target=sum_values, args=(N // 2, N, shared_value))\n",
    "\n",
    "    process1.start()\n",
    "    process2.start()\n",
    "\n",
    "    process1.join()\n",
    "    process2.join()\n",
    "    return shared_value.value\n",
    "\n",
    "# Add code below\n",
    "\n",
    "results = []\n",
    "for _ in range(10) : \n",
    "    results.append(sum_with_two_processes())\n",
    "\n",
    "print(results)\n",
    "```\n",
    "\n",
    "## Using lock to prevent overwitting \n",
    "\n",
    "multiprocess를 사용하면서 발생하는 shared memory에 값을 덮어쓰는 문제는 **lock**을 통해 해결할 수 있다. lock은 병렬처리에서 각각의 프로세스의 자원을 통제하는 매커니즘으로, 다른 프로세스가 각 자원에 서로 간섭하는 것을 방지하도록 한다. 해당 작업은 Value.get_loc() 메소드를 사용함으로써 가능하다. \n",
    "\n",
    "하지만 이 방식은 병렬처리의 이점을 더이상 살리지 못한다. 다른 프로세스 해당 프로세스가 잠겨있는 동안 shared memory에 접근할 수 없기 때문이다. 이는 지역변수를 설정하고 지역변수의 값에 업데이트 하는 방식으로 해결할 수 있다. \n",
    "\n",
    "```Python\n",
    "def sum_values(first, last, shared_value):\n",
    "    for i in range(first, last):\n",
    "        with shared_value.get_lock():\n",
    "            shared_value.value += i\n",
    "            \n",
    "def sum_values_improved(first, last, shared_value) : \n",
    "    value_sum = 0\n",
    "    for i in range(first, last) : \n",
    "        value_sum += i \n",
    "    with shared_value.get_lock() : \n",
    "        shared_value.value = value_sum\n",
    "\n",
    "def measure_runtime(function_to_measure):\n",
    "    N = 10000\n",
    "    shared_value = multiprocessing.Value(\"i\")\n",
    "    process1 = multiprocessing.Process(target=function_to_measure, args=(1, N // 2, shared_value))\n",
    "    process2 = multiprocessing.Process(target=function_to_measure, args=(N // 2, N, shared_value))\n",
    "    start = time.time()\n",
    "    process1.start()\n",
    "    process2.start()\n",
    "    process1.join()\n",
    "    process2.join()\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "    \n",
    "# Whole calculation\n",
    "start = time.time()\n",
    "res = 0\n",
    "for i in range(1, 10000) : \n",
    "    res += i\n",
    "end = time.time()\n",
    "elapsed1 = end - start \n",
    "\n",
    "time_sum_values = measure_runtime(sum_values) \n",
    "time_sum_values_improved = measure_runtime(sum_values_improved)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d665d41",
   "metadata": {},
   "source": [
    "# Process Pool Executors\n",
    "\n",
    "## Make frequency table of each languages \n",
    "\n",
    "job_postings 데이터테이블에 작성되어 있는 언어별 빈도수 테이블을 생성하려고 한다. Series.str.count() 메소드는 행을 기준으로 각 행의 count에 입력된 argument가 얼마나 반복되었는지를 계산한다. 이후 sum() 메소드를 통해 언어별 총 빈도수를 확인할 수 있다.\n",
    "\n",
    "\n",
    "```Python\n",
    "import pandas as pd \n",
    "job_postings = pd.read_csv('DataEngineer.csv') \n",
    "num_rows = job_postings.shape[0]\n",
    "num_cols = job_postings.shape[1]\n",
    "\n",
    "job_postings[\"Job Description\"] = job_postings[\"Job Description\"].str.lower()\n",
    "\n",
    "# Make frequency table \n",
    "skills = pd.read_csv('Skills.csv')\n",
    "frequency = {}\n",
    "\n",
    "for skill_name in skills[\"Name\"] : \n",
    "    frequency[skill_name] = job_postings[\"Job Description\"].str.count(skill_name).sum()\n",
    "print(frequency[\"programming\"])\n",
    "```\n",
    "\n",
    "## Function of frequency table \n",
    "\n",
    "병렬처리를 위한 첫 단계는 코드를 함수로 변환하는 작업이다. 빈도표를 작성하는 코드를 job_postings와 skills를 입력받는 count_skills() 내부에 작성하여 함수를 생성한다.\n",
    "\n",
    "```Python\n",
    "import time\n",
    "\n",
    "def count_skills(job_postings, skills) : \n",
    "    frequency = {}\n",
    "    for skill_name in skills[\"Name\"]:\n",
    "        frequency[skill_name] = job_postings[\"Job Description\"].str.count(skill_name).sum()\n",
    "    return frequency\n",
    "    \n",
    "start = time.time()\n",
    "count_skills(job_postings, skills) \n",
    "end = time.time()\n",
    "runtime = end - start\n",
    "print(runtime)\n",
    "```\n",
    "\n",
    "## Function of dataframe chunk\n",
    "\n",
    "데이터셋이 가용 메모리에 적합하지 않을 경우 청크 단위로 나누어 데이터를 처리하였다. 따라서 병렬처리를 위한 데이터셋을 청크 단위로 분해하는 함수를 작성한다. 입력된 청크의 수에 따라 처리해야하는 청크의 크기는 math.ceil() 메소드를 통해 계산하고 ragne(0, num_rows, chunk_size)를 통해 데이터 셋을 분할할 수 있다. \n",
    "\n",
    "```Python\n",
    "import math\n",
    "def math_chunks(df, num_chunks) : \n",
    "    num_rows = df.shape[0]\n",
    "    chunk_size = math.ceil(num_rows/num_chunks)\n",
    "    return [df[i:i+chunk_size] for i in range(0, num_rows, chunk_size)]\n",
    "    \n",
    "skill_chunks = math_chunks(skills, 8)\n",
    "```\n",
    "\n",
    "## Process Pool Executor\n",
    "\n",
    "Job Description에 기술되어 있는 언어에 대한 빈도표를 청크 단위로 병렬 처리하는 workflow는 아래와 같다.\n",
    "\n",
    "1. split the data into chunks \n",
    "2. create a process list, one for each chunk\n",
    "3. run all processes and wait for them to finish \n",
    "4. gather the results and merge them into a single frequency table \n",
    "\n",
    "4번째 단계의 경우 multiprocessing.Value 객체는 하나의 값만 저장하기 때문에 문제가 발생할 수 있다. concurrent.futures 모듈은 실행된 각각의 프로세스의 값을 리스트의 형태로 저장할 수 있다. concurrent.futures.ProcessPoolExecutor context manager는 각각의 프로세스를 함수, 입력값을 입력받아 실행하여 값을 list의 형태로 저장할 수 있다. 프로세스를 실행하기 위해 Executor.submit() 메소드를 사용하여 with statement 내부에서 작동하기 때문에 프로세스를 자동 종료시킨다. Executor.submit()으로 생성된 Future 객체는 Future.result()를 통해 결과를 불러올 수 있다. \n",
    "\n",
    "```Python\n",
    "import concurrent.futures\n",
    "\n",
    "def increment(value):\n",
    "    return value + 1\n",
    "\n",
    "values = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor : \n",
    "    futures = [executor.submit(increment, value) for value in values] \n",
    "    \n",
    "results = [future.result() for future in futures]\n",
    "```\n",
    "\n",
    "## Parallel Processing of frequency table \n",
    "\n",
    "1. job_postings 데이터프레임을 분할하고 각각의 청크에 있는 모든 skill을 샌다. 각각의 프로세스는 job_posting의 부분을 입력받아 빈도표를 작성한다.\n",
    "2. skills를 분할하여 각 청크에 대해 job_postings 천체 데이터프레임에 대해 분할표를 작성한다. \n",
    "\n",
    "### First case \n",
    "\n",
    "```Python\n",
    "import concurrent.futures\n",
    "import pandas as pd \n",
    "import math \n",
    "\n",
    "def count_skills(df, skills) :\n",
    "    frequency = {}\n",
    "    for skill_name in skills[\"Name\"] : \n",
    "        frequency[skill_name] = df[\"Job Description\"].str.count(skill_name).sum()\n",
    "    return frequency\n",
    "\n",
    "def make_chunks(df, chunk_size) : \n",
    "    num_rows = df.shape[0]\n",
    "    chunk_size = math.ceil(num_rows / chunk_size) \n",
    "    return [df[i:i+chunk_size] for i in range(0, num_rows, chunk_size)]\n",
    "\n",
    "job_chunks = make_chunks(job_postings, 8) \n",
    "with current.futures.ProcessPoolExecutor() as executor : \n",
    "    futures = [executor.submit(count_skills, job_chunk, skills) for job_chunk in job_chunks]\n",
    "results = [future.result() for future in futures]\n",
    "\n",
    "merged_results = {} \n",
    "for result in results : \n",
    "    for language in result : \n",
    "        if language in merged_results : \n",
    "            merged_results[language] += result[language]\n",
    "        else : \n",
    "            merged_results[language] = result[language] \n",
    "```\n",
    "\n",
    "### Second case \n",
    "\n",
    "```Python\n",
    "import concurrent.futures\n",
    "import pandas as pd \n",
    "import math \n",
    "\n",
    "def count_skills(job_postings, skills) :\n",
    "    frequency = {}\n",
    "    for skill_name in skills[\"Name\"] : \n",
    "        frequency[skill_name] = job_postings[\"Job Description\"].str.count(skill_name).sum()\n",
    "    return frequency\n",
    "\n",
    "def make_chunks(df, chunk_size) : \n",
    "    num_rows = df.shape[0]\n",
    "    chunk_size = math.ceil(num_rows / chunk_size) \n",
    "    return [df[i:i+chunk_size] for i in range(0, num_rows, chunk_size)]\n",
    "\n",
    "skill_chunks = make_chunks(skills, 8) \n",
    "with concurrent.futures.ProcessPoolExecutor() as executor : \n",
    "    futures = [executor.submit(count_skills, job_postings, skill_chunk) for skill_chunk in skill_chunks]\n",
    "results = [future.result() for future in futures]\n",
    "\n",
    "merged_results = {}\n",
    "for result in results : \n",
    "    merged_results.update(result) \n",
    "print(merged_results)\n",
    "```\n",
    "\n",
    "## Time Comparison\n",
    "\n",
    "```Python\n",
    "def count_skills(job_postings, skills):\n",
    "    frequency = {}\n",
    "    for skill_name in skills[\"Name\"]:\n",
    "        frequency[skill_name] = job_postings[\"Job Description\"].str.count(skill_name).sum()\n",
    "    return frequency\n",
    "\n",
    "def count_skills_parallel(job_postings, skills, num_processes=4):\n",
    "    # Calculate results using paralleld processing\n",
    "    skill_chunks = make_chunks(skills, num_processes)\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        futures = [executor.submit(count_skills, job_postings, skill_chunk) for skill_chunk in skill_chunks]\n",
    "    results = [future.result() for future in futures]\n",
    "    # Merge results\n",
    "    merged_results = {}\n",
    "    for result in results:\n",
    "        merged_results.update(result)\n",
    "    return merged_results\n",
    "\n",
    "import time\n",
    "\n",
    "# Measure execution times \n",
    "start = time.time()\n",
    "count_skills(job_postings, skills)\n",
    "end = time.time()\n",
    "time_normal = end - start \n",
    "\n",
    "start = time.time()\n",
    "count_skills_parallel(job_postings, skills, num_processes = 4)\n",
    "end = time.time()\n",
    "time_parallel = end - start\n",
    "\n",
    "print(time_normal/time_parallel)\n",
    "```\n",
    "\n",
    "병렬처리를 한 경우가 하지 않은 경우에 비해 2배가량 빠르다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d85a31d",
   "metadata": {},
   "source": [
    "# Introduction to MapReduce\n",
    "\n",
    "## What is MapReduce \n",
    "\n",
    "**맵리듀스(MapReduce)**는 구글에서 대용량 처리를 분산 병렬 컴퓨팅에서 처리하기 위한 목적으로 제작된 스프트웨어 프레임워크이다. 이 프레임워크는 페타바이트 이상의 대용량 데이터를 신뢰도가 낮은 컴퓨터로 구성된 클러스터 환경에서 병렬 처리를 지원하기 위해서 개발되었다. 대표적으로 Apache Hadoop에서 Open Soruce Software로 적용되었다.\n",
    "\n",
    "맵리듀스의 개념은 Process Pool Executors에서 사용한 방식과 유사하다. \n",
    "\n",
    "1. Divide : Divide the data into chunks \n",
    "2. Map : Use parallel processing to process each chunk\n",
    "3. Reduce : Combine the individual chunk result into a global result \n",
    "\n",
    "이전에 작업했던 병렬 컴퓨팅 프로그램에서 Divide 단계는 make_chunks를, Map 단계는 count_skills를, Reduce 단계는 Future.result()의 결과를 단일 데이터프레임으로 병합한 작업과 동일하다. MapReduec에서 병렬처리는 Map 단계에서 시행된다. \n",
    "\n",
    "## Generalize multiprocessing \n",
    "\n",
    "### Divide \n",
    "\n",
    "병렬 처리에 사용했던 함수를 MapReduce framework에 적용하기 위해선 기존에 사용하던 함수를 데이터 타입에 상관없이 일반화할 필요가 있다. 시행 결과 list 객체에 대해서도 make_chunks() 함수가 작동하는 것을 확인할 수 있다.  \n",
    "\n",
    "```Python\n",
    "import math\n",
    "\n",
    "def make_chunks(data, num_chunks):\n",
    "    chunk_size = math.ceil(len(data) / num_chunks)\n",
    "    return [data[i:i+chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "\n",
    "chunks = make_chunks([1, 2, 3, 4, 5, 6], 3)\n",
    "print(chunks)\n",
    "```\n",
    "\n",
    "### Map\n",
    "\n",
    "데이터 타입과 관계없는 청크를 생산하는 함수를 작성했다면 입력받은 함수에 대해 병렬처리(Map)를 해서 청크 별 결과를 산출해야 한다.. map_parallel() 함수는 함수 mapper, data, num_processes(chunk size)를 입력받아 MapReduce 전체 과정을 처리하게 된다. \n",
    "\n",
    "- mapper : the function that we want to apply to each chunk. \n",
    "- data : the data\n",
    "- num_processes : the number of processes to use \n",
    "\n",
    "```Python\n",
    "import concurrent.futures\n",
    "\n",
    "def map_parallel(mapper, data, num_processes):\n",
    "    chunks = make_chunks(data, num_processes)\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        futures = [executor.submit(mapper, chunk) for chunk in chunks]\n",
    "    return [future.result() for future in futures]\n",
    "\n",
    "values = [1, 4, 5, 2, 7, 21,     \\\n",
    "          31, 41, 3, 40, 5, 14,  \\\n",
    "          9, 32, 12, 18, 1, 30,  \\\n",
    "          6, 19, 23, 35, 12, 13, \\\n",
    "          0, 12, 42, 41, 11, 9]\n",
    "\n",
    "results = map_parallel(max, values, 5) \n",
    "print(results)\n",
    "```\n",
    "\n",
    "## Pool\n",
    "\n",
    "multiprocessing.Pool은 concurrent.futures.ProcessPoolExecutor()없이 나누어진 데이터에 대해 병렬처리를 수행할 수 있다. Pool() 내부에는 프로세스의 수를입력할 수 있으며 default값은 os.cpu_count()에 저장되어 있는 CPU의 수이다. \n",
    "\n",
    "생성된 Pool 객체는 Pool.map() 메소드를 통해 프로세스에 사용할 함수와 데이터 집합을 사용할 수 있다. concurrent.futures.ProcessPoolExecutor() 와는 다르게 실행된 프로세스를 종료하고 다른 프로세스가 끝날때까지 기다리기 위해 Pool.close()와 Pool.join() 메소드를 사용한다. \n",
    "\n",
    "```Python\n",
    "values = [1, 4, 5, 2, 7, 21,     \\\n",
    "          31, 41, 3, 40, 5, 14,  \\\n",
    "          9, 32, 12, 18, 1, 30,  \\\n",
    "          6, 19, 23, 35, 12, 13, \\\n",
    "          0, 12, 42, 41, 11, 9]\n",
    "\n",
    "chunks = make_chunks(values, 6)\n",
    "\n",
    "from multiprocessing import Pool\n",
    "pool = Pool(6) \n",
    "results = pool.map(max, chunks) \n",
    "pool.close()\n",
    "pool.join()\n",
    "```\n",
    "\n",
    "사실 Pool.map() 메소드는 해당 프로세스가 종료될때까지 자동으로 시행을 막기때문에 Pool.join() 메소드를 사용할 필요가 없다. Pool.close() 메소드의 경우 반드시 사용되어야 한다. concurrent.futures.ProcessPoolExecutor()와 같이 context manager를 사용하면 코드를 작성하는데 편할 뿐만아니라, Pool.close() 메소드를 사용할 필요가 없다. \n",
    "\n",
    "```Python\n",
    "values = [1, 4, 5, 2, 7, 21,     \\\n",
    "          31, 41, 3, 40, 5, 14,  \\\n",
    "          9, 32, 12, 18, 1, 30,  \\\n",
    "          6, 19, 23, 35, 12, 13, \\\n",
    "          0, 12, 42, 41, 11, 9]\n",
    "\n",
    "chunks = make_chunks(values, 6)\n",
    "\n",
    "with Pool(6) as pool : \n",
    "    results = pool.map(max, chunks)\n",
    "print(results)\n",
    "```\n",
    "\n",
    "## Reduce \n",
    "\n",
    "**functools module**의 reduce 함수는 각각의 데이터 청크에 적용한 함수의 결과를 취합하여 전체 결과를 만드는데 유용하게 사용된다. functools.reduce() 메소드는 각각 reducer function과 reduce function을 적용하고자 하는 데이터 청크를 입력받는다. functools.reduce()에 함수와 데이터가 입력되면, 각각의 원소를 순차적으로 함수에 적용하여 최종 결과를 산출한다. (자동으로 for loop가 적용되게 된다)\n",
    "\n",
    "```python\n",
    "values = [1, 4, 5, 2, 7, 21,     \\\n",
    "          31, 41, 3, 40, 5, 14,  \\\n",
    "          9, 32, 12, 18, 1, 30,  \\\n",
    "          6, 19, 23, 35, 12, 13, \\\n",
    "          0, 12, 42, 41, 11, 9]\n",
    "\n",
    "import functools \n",
    "max_value = functools.reduce(max, values)\n",
    "```\n",
    "\n",
    "## Workflow of MapReduce \n",
    "\n",
    "입력된 데이터 중 최대값을 산출하는 프로세스를 MapReduce를 기반으로 구현한다고 할 때, 다음과 같은 workflow로 진행될 수 있다.\n",
    "\n",
    "- Divide : make_chunks()를 사용해서 데이터를 분해\n",
    "- Map : Pool.map()을 사용해서 각각의 청크에 대해 max 함수를 적용\n",
    "- Reduce : functools.reduce() 메소드를 사용해서 산출된 결과에서 단일값을 추출\n",
    "\n",
    "```Python\n",
    "data = [1, 4, 5, 2, 7, 21,     \\\n",
    "        31, 41, 3, 40, 5, 14,  \\\n",
    "        9, 32, 12, 18, 1, 30,  \\\n",
    "        6, 19, 23, 35, 12, 13, \\\n",
    "        0, 12, 42, 41, 11, 9]\n",
    "\n",
    "num_processes = 5\n",
    "\n",
    "# Divide \n",
    "def make_chunks(data, num_processes) : \n",
    "    chunk_size = math.ceil(len(data) / num_processes) \n",
    "    return [data[i : i+chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "chunks = make_chunks(data, num_processes)\n",
    "\n",
    "# Map \n",
    "with Pool(num_processes) as pool : \n",
    "    chunk_results = pool.map(max, chunks) \n",
    "\n",
    "# Reduce \n",
    "overall_result = functools.reduce(max, results)\n",
    "print(overall_result)\n",
    "\n",
    "# All in one \n",
    "\n",
    "def make_chunks(data, num_processes) : \n",
    "    chunk_size = math.ceil(len(data) / num_processes) \n",
    "    return [data[i : i+chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "\n",
    "def map_reduce(data, num_processes, mapper, reducer):\n",
    "    chunks = make_chunks(data, num_processes)\n",
    "    with Pool(num_processes) as pool:\n",
    "        chunk_results = pool.map(mapper, chunks)\n",
    "    return functools.reduce(reducer, chunk_results)\n",
    "```\n",
    "\n",
    "## Apply mapreduce to dataframe \n",
    "\n",
    "기존에 job_postings에서 언어별 빈도표를 작성하는 두가지 workflow이다. 각 workflow를 Process Pool Executors를 사용하여 언어별 빈도표를 작성하는 것이 아닌, MapReduce framework를 사용하여 코드를 구성해야한다. \n",
    "\n",
    "1. job_postings 데이터프레임을 분할하고 각각의 청크에 있는 모든 skill을 샌다. 각각의 프로세스는 job_posting의 부분을 입력받아 빈도표를 작성한다.\n",
    "2. skills를 분할하여 각 청크에 대해 job_postings 천체 데이터프레임에 대해 분할표를 작성한다.\n",
    "\n",
    "MapReduce의 workflow는 Divide - Map - Reduce로 데이터를 처리하여 하나의 결과만을 출력한다. main function인 map_reduce는 Map 단계와 Reduce 단계에서 적용되는 함수가 상이할 수 있기때문에 mapper와 reducer로 분리하여 함수를 입력받는다. \n",
    "\n",
    "1. Divide : Divide the data into chunks \n",
    "2. Map : Use parallel processing to process each chunk\n",
    "3. Reduce : Combine the individual chunk result into a global result \n",
    "\n",
    "### First case \n",
    "\n",
    "- make_chunks : job_postings를 나누어 job_chunks를 생성\n",
    "- mapper : 각각의 job_chunks에 대해 skills 별로 빈도표 생성 \n",
    "- reducer : 각각의 빈도표에 저장되어 있는 값을 서로 더함 \n",
    "\n",
    "```Python\n",
    "import pandas as pd\n",
    "job_postings = pd.read_csv(\"DataEngineer.csv\")\n",
    "job_postings[\"Job Description\"] = job_postings[\"Job Description\"].str.lower()\n",
    "skills = pd.read_csv(\"Skills.csv\")\n",
    "\n",
    "def make_chunks(data, num_processes) : \n",
    "    chunk_size = math.ceil(len(data) / num_processes) \n",
    "    return [data[i : i+chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "\n",
    "def map_reduce(data, num_processes, mapper, reducer):\n",
    "    chunks = make_chunks(data, num_processes)\n",
    "    with Pool(num_processes) as pool:\n",
    "        chunk_results = pool.map(mapper, chunks)\n",
    "    return functools.reduce(reducer, chunk_results)\n",
    "\n",
    "def mapper(jobs_chunk) : \n",
    "    frequency = {} \n",
    "    for skill_name in skills[\"Name\"] : \n",
    "        frequency[skill_name] = jobs_chunk[\"Job Description\"].str.count(skill_name).sum() \n",
    "    return frequency \n",
    "\n",
    "def reducer(freq_chunk1, freq_chunk2) : \n",
    "    merged = {} \n",
    "    for skill in freq_chunk1 : \n",
    "        merged[skill] = freq_chunk1[skill] + freq_chunk2[skill]\n",
    "    return merged\n",
    "\n",
    "skill_freq = map_reduce(job_postings, 4, mapper, reducer)\n",
    "```\n",
    "\n",
    "### Second case \n",
    "\n",
    "- make_chunks : skills를 나누어 skill_chunks를 생성\n",
    "- mapper : 각각의 skill_chunks에 대해 빈도표 생성\n",
    "- reducer : 각각의 빈도표를 하나의 데이터에 저장 \n",
    "\n",
    "```Python\n",
    "import pandas as pd\n",
    "job_postings = pd.read_csv(\"DataEngineer.csv\")\n",
    "job_postings[\"Job Description\"] = job_postings[\"Job Description\"].str.lower()\n",
    "skills = pd.read_csv(\"Skills.csv\")\n",
    "\n",
    "def make_chunks(data, num_processes) : \n",
    "    chunk_size = math.ceil(len(data) / num_processes) \n",
    "    return [data[i : i+chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "\n",
    "def map_reduce(data, num_processes, mapper, reducer):\n",
    "    chunks = make_chunks(data, num_processes)\n",
    "    with Pool(num_processes) as pool:\n",
    "        chunk_results = pool.map(mapper, chunks)\n",
    "    return functools.reduce(reducer, chunk_results)\n",
    "\n",
    "def mapper(skill_chunk) : \n",
    "    frequency = {} \n",
    "    for skill_name in skill_chunk[\"Name\"] : \n",
    "        frequency[skill_name] = job_postings[\"Job Description\"].str.count(skill_name).sum() \n",
    "    return frequency \n",
    "\n",
    "def reducer(freq_chunk1, freq_chunk2) : \n",
    "    freq_chunk1.update(freq_chunk2)\n",
    "    return freq_chunk1 \n",
    "\n",
    "skill_freq = map_reduce(skills, 4, mapper, reducer)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ef7808",
   "metadata": {},
   "source": [
    "# Processing data with MapReduce\n",
    "\n",
    "## MapReduce Framework \n",
    "\n",
    "MapReduce를 진행하기 위해 생성했던 map_reduce() 함수는 다음의 arguments를 입력받는다. 이때 mapper function은 데이터를 분리한 청크에 대해 적용할 함수를 의미하며, reducer function은 mapper function에 의해 생성된 연산 결과를 하나의 연산 결과로 만드는 함수이다. \n",
    "\n",
    "- The data\n",
    "- The number of processes \n",
    "- The mapper function\n",
    "- The reducer function\n",
    "\n",
    "## Calculate the length of the longest word \n",
    "\n",
    "- mapper function : 각각의 chunk의 가장 긴 단어의 길이를 계산 \n",
    "- reducer function : 각각의 chunk의 가장 긴 단어의 길이중 최댓값 계산 \n",
    "\n",
    "```Python\n",
    "with open(\"english_words.txt\") as f:\n",
    "    words = [word.strip() for word in f.readlines()]\n",
    "    \n",
    "def map_max_length(words_chunk) : \n",
    "    max_length = 0 \n",
    "    for word in words_chunk : \n",
    "        if len(word) > max_length : \n",
    "            max_length = len(word) \n",
    "    return max_length\n",
    "\n",
    "max_len = map_reduce(words, 4, map_max_length, max)\n",
    "```\n",
    "\n",
    "## Retreive the longest word \n",
    "\n",
    "- mapper function : 각각의 chunk의 가장 긴 단어를 계산 (max(key = len) 사용) \n",
    "- reducer function : word1, word2에 대해서 길이가 긴 단어를 계산 \n",
    "\n",
    "```Python\n",
    "with open(\"english_words.txt\") as f:\n",
    "    words = [word.strip() for word in f.readlines()]\n",
    "    \n",
    "def map_max_len_str(words_chunk) : \n",
    "    return max(words_chunk, key = len) \n",
    "\n",
    "def reduce_max_len_str(word1, word2) : \n",
    "    if len(word1) >= len(word2) :\n",
    "        return word1\n",
    "    return word2\n",
    "\n",
    "max_len_str = map_reduce(words, 4, map_max_len_str, reduce_max_len_str)\n",
    "```\n",
    "\n",
    "## Retrieve extence of word \n",
    "\n",
    "영어 사전의 알파벳을 검색하고자 할때 Mapreduce를 사용하는 경우 속도면에서 훨씬 빠른 검색 속도를 가능하게 한다. \n",
    "\n",
    "- mapper function : 각각의 chunk에 target 단어가 존재하는지 True/False return\n",
    "- reducer function : logical1, logical2에 대해서 Any true를 계산하기 위해 or 연산 계산 \n",
    "\n",
    "```Python\n",
    "with open(\"english_words.txt\") as f:\n",
    "    words = [word.strip() for word in f.readlines()]\n",
    "\n",
    "target = \"pneumonoultramicroscopicsilicovolcanoconiosis\"\n",
    "\n",
    "def map_contains(words_chunk) : \n",
    "    if target in words_chunk : \n",
    "        return True \n",
    "    return False \n",
    "\n",
    "def reduce_contains(contains1, contains2) : \n",
    "    return contains1 or contains2 \n",
    "\n",
    "is_contained = map_reduce(words, 4, map_contains, reduce_contains)\n",
    "```\n",
    "\n",
    "## Counting the frequency of the characters throughout the entire list of words \n",
    "\n",
    "- mapper function : 각각의 chunk에 존재하는 알파벳의 빈도표 계산 \n",
    "- reducer function : freq1, freq2를 하나로 합침 (존재하지 않는 값에 대해 연산 필요) \n",
    "\n",
    "```Python\n",
    "with open(\"english_words.txt\") as f:\n",
    "    words = [word.strip() for word in f.readlines()]\n",
    "    \n",
    "def map_char_count(words_chunk) : \n",
    "    char_freq = {}\n",
    "    for word in words_chunk : \n",
    "        for c in word : \n",
    "            if c not in char_freq : \n",
    "                char_freq[c] = 0\n",
    "            char_freq[c] += 1\n",
    "    return char_freq\n",
    "                \n",
    "def reduce_char_count(freq1, freq2) : \n",
    "    for c in freq2 : \n",
    "        if c in freq1 : \n",
    "            freq1[c] += freq2[c]\n",
    "        else : \n",
    "            freq1[c] = freq2[c]\n",
    "    return freq1\n",
    "            \n",
    "char_freq = map_reduce(words, 4, map_char_count, reduce_char_count)\n",
    "```\n",
    "\n",
    "## Calculate the average length of English words \n",
    "\n",
    "- mapper function : 각각의 chunk에 존재하는 알파벳의 합 / 전체 단어의 수 계산 \n",
    "- reducer function : res1, res2를 더하여 평균값 계산 \n",
    "\n",
    "```Python\n",
    "with open(\"english_words.txt\") as f:\n",
    "    words = [word.strip() for word in f.readlines()]\n",
    "    \n",
    "def map_average(words_chunk) : \n",
    "    tot_sum = 0 \n",
    "    for word in words_chunk : \n",
    "        tot_sum += len(word) \n",
    "    return tot_sum / len(words) \n",
    "\n",
    "def reduce_average(res1, res2) : \n",
    "    return res1 + res2\n",
    "\n",
    "average_word_len = map_reduce(words, 4, map_average, reduce_average)\n",
    "```\n",
    "\n",
    "## Find which pairs of characters occurs next to each other in only one word \n",
    "\n",
    "- mapper function : 각각의 chunk에 존재하는 모든 알파벳 쌍의 빈도표 계산\n",
    "- reducer function : freq1, freq2를 하나로 합침 \n",
    "\n",
    "```Python\n",
    "with open(\"english_words.txt\") as f:\n",
    "    words = [word.strip() for word in f.readlines()]\n",
    "    \n",
    "def map_adjacent(words_chunk) : \n",
    "    freq_pairs = {} \n",
    "    for word in words_chunk : \n",
    "        for i in range(len(word) - 1) : \n",
    "            seq = word[i] + word[i + 1]\n",
    "            if seq not in freq_pairs : \n",
    "                freq_pairs[seq] = 0\n",
    "            freq_pairs[seq] += 1\n",
    "    return freq_pairs \n",
    "\n",
    "def reduce_adjacent(freq1, freq2) :\n",
    "    for pair in freq2 : \n",
    "        if pair in freq1 : \n",
    "            freq1[pair] += freq2[pair]\n",
    "        else : \n",
    "            freq1[pair] = freq2[pair]\n",
    "    return freq1 \n",
    "\n",
    "pair_freq = map_reduce(words, 4, map_adjacent, reduce_adjacent) \n",
    "unique_pairs = [pair for pair in pair_freq if pair_freq[pair] == 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c58f33e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
