{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c1ce324",
   "metadata": {},
   "source": [
    "# <center> Import library function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84dd0aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import missingno as msno\n",
    "    \n",
    "# Data View\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "# Import Basic Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "    \n",
    "# Data Visualization : Plotly library \n",
    "import chart_studio.plotly as py\n",
    "import cufflinks as cf\n",
    "cf.go_offline(connected = True )\n",
    "    \n",
    "import plotly.express as px\n",
    "    \n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "    \n",
    "from plotly.subplots import make_subplots \n",
    "import plotly.figure_factory as ff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe04bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly Dash \n",
    "# Prerequsite\n",
    "import dash \n",
    "import dash_core_components as dcc\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_html_components as html\n",
    "import dash_table\n",
    "from dash.dependencies import Input, Output\n",
    "from jupyter_dash import JupyterDash \n",
    "\n",
    "# Data Analysis \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Making figure\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Operate Dash on jupyterlab\n",
    "from jupyter_dash import JupyterDash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4273d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing \n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_predict, GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, PolynomialFeatures\n",
    "\n",
    "# Model Construction\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Model\n",
    "\n",
    "\n",
    "# Model Evaluation\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cb6c2a",
   "metadata": {},
   "source": [
    "# <center> Data glimpse function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17447385",
   "metadata": {},
   "source": [
    "# 1. Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0150091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing(df) : \n",
    "    missing_number = df.isnull().sum().sort_values(ascending = False)\n",
    "    missing_percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending = False)\n",
    "    missing_values = pd.concat([missing_number, missing_percent], axis = 1, keys = ['Missing_number', 'Missing_percent'])\n",
    "    return missing_values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b35ea8",
   "metadata": {},
   "source": [
    "# 2. Column categorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b451e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(df) :\n",
    "    Quantitive_features = df.select_dtypes([np.number]).columns.tolist()\n",
    "    Categorical_features = df.select_dtypes(exclude = [np.number]).columns.tolist()\n",
    "    Discrete_features = [col for col in Quantitive_features if len(df[col].unique()) < 10]\n",
    "    Continuous_features = [col for col in Quantitive_features if col not in Discrete_features]\n",
    "    print(f\"Quantitive feautres : {Quantitive_features} \\nDiscrete features : {Discrete_features} \\nContinous features : {Continuous_features} \\nCategorical features : {Categorical_features}\\n\")\n",
    "    print(f\"Number of quantitive feautres : {len(Quantitive_features)} \\nNumber of discrete features : {len(Discrete_features)} \\nNumber of continous features : {len(Continuous_features)} \\nNumber of categorical features : {len(Categorical_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6dcbc4",
   "metadata": {},
   "source": [
    "# 3. Final code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337ae0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing(df) : \n",
    "    \"\"\"\n",
    "    This function shows number of missing values and its percetages \n",
    "    \"\"\"\n",
    "    missing_number = df.isnull().sum().sort_values(ascending = False)\n",
    "    missing_percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending = False)\n",
    "    missing_values = pd.concat([missing_number, missing_percent], axis = 1, keys = ['Missing_number', 'Missing_percent'])\n",
    "    return missing_values \n",
    "\n",
    "def categorize(df) :\n",
    "    \"\"\"\n",
    "    This function shows number of features by dtypes.\n",
    "    Result of function is not always accruate because this result estimate dtypes before preprocessing.\n",
    "    \"\"\"\n",
    "    Quantitive_features = df.select_dtypes([np.number]).columns.tolist()\n",
    "    Categorical_features = df.select_dtypes(exclude = [np.number]).columns.tolist()\n",
    "    Discrete_features = [col for col in Quantitive_features if len(df[col].unique()) < 10]\n",
    "    Continuous_features = [col for col in Quantitive_features if col not in Discrete_features]\n",
    "    print(f\"Quantitive feautres : {Quantitive_features} \\nDiscrete features : {Discrete_features} \\nContinous features : {Continuous_features} \\nCategorical features : {Categorical_features}\\n\")\n",
    "    print(f\"Number of quantitive feautres : {len(Quantitive_features)} \\nNumber of discrete features : {len(Discrete_features)} \\nNumber of continous features : {len(Continuous_features)} \\nNumber of categorical features : {len(Categorical_features)}\")\n",
    "    \n",
    "def unique(df) : \n",
    "    \"\"\"\n",
    "    This function returns table storing number of unique values and its samples.\n",
    "    \"\"\"\n",
    "    tb1 = pd.DataFrame({'Columns' : df.columns, 'Number_of_Unique' : df.nunique().values.tolist(),\n",
    "                       'Sample1' : df.sample(1).values.tolist()[0], 'Sample2' : df.sample(1).values.tolist()[0], \n",
    "                       'Sample3' : df.sample(1).values.tolist()[0],\n",
    "                       'Sample4' : df.sample(1).values.tolist()[0], 'Sample5' : df.sample(1).values.tolist()[0]})\n",
    "    return tb1    \n",
    "\n",
    "def data_glimpse(df) :   \n",
    "    \n",
    "    # Dataset preview \n",
    "    print(\"1. Dataset Preview \\n\")\n",
    "    display(df.head())\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    # Columns imformation\n",
    "    print(\"2. Column Information \\n\")\n",
    "    print(f\"Dataset have {df.shape[0]} columns and {df.shape[1]} rows\")\n",
    "    print(\"\\n\") \n",
    "    print(f\"Dataset Column name : {df.columns.values}\")\n",
    "    print(\"\\n\")\n",
    "    categorize(df)\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    # Basic imformation table \n",
    "    print(\"3. Missing data table : \\n\")\n",
    "    display(missing(df))\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    print(\"4. Number of unique value by column : \\n\")\n",
    "    display(unique(df))\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    print(\"5. Describe table : \\n\")\n",
    "    display(df.describe())\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    print(df.info())\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e60b05",
   "metadata": {},
   "source": [
    "# <Center> Visualization Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2d5c5",
   "metadata": {},
   "source": [
    "# 1. Quantitive + Univariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c1defe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantitive_Univariate_Plot(df, fea) : \n",
    "    fig = make_subplots(rows = 1, cols = 2)\n",
    "\n",
    "    fig.add_trace(go.Histogram(\n",
    "        x = df[fea],\n",
    "        name = 'Histogram'\n",
    "        ),\n",
    "        row = 1, col = 1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(go.Box(\n",
    "        y = df[fea],\n",
    "        name = 'Box plot'\n",
    "        ),\n",
    "        row = 1, col = 2\n",
    "    )\n",
    "    fig.update_xaxes(title_text= \"Value\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text= fea, row=1, col=2)\n",
    "    fig.update_yaxes(title_text= \"Count\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text= \"Value\", row=1, col=2)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e468e1",
   "metadata": {},
   "source": [
    "# 2. Categorical + Univarate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f9f8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Categorical_Features_Univarate(df, fea) : \n",
    "    length = len(df[fea].value_counts().keys())\n",
    "    colors = px.colors.sequential.RdBu[:length]\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        x = df[fea].value_counts(),\n",
    "        y = df[fea].value_counts().keys(),\n",
    "        orientation = 'h',\n",
    "        marker_color = colors))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c2d867",
   "metadata": {},
   "source": [
    "# 3. Quantitive + Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd306b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantitive_Multivariate(df, fea) : \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Box( \n",
    "            y = df_train_raw.loc[df.Risk_Flag == 1, fea],\n",
    "            name = 'risk')\n",
    "    )\n",
    "    fig.add_trace(\n",
    "         go.Box(\n",
    "            y = df_train_raw.loc[df.Risk_Flag == 0, fea],\n",
    "            name = 'non_risk')\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        {\n",
    "            \"title\": {\n",
    "                \"text\": \"<b>Multivariate Analysis between {} and Risk_Flags</b>\".format(fea),\n",
    "                \"x\": 0.5,\n",
    "                \"y\": 0.9,\n",
    "                \"font\": {\n",
    "                    \"size\": 15\n",
    "                }\n",
    "            },\n",
    "            \"xaxis\": {\n",
    "                \"title\": \"Risk_Flags\",\n",
    "                \"tickfont\": {\n",
    "                    \"size\": 10                \n",
    "                }\n",
    "            },\n",
    "            \"yaxis\": {\n",
    "                \"title\": fea,\n",
    "                \"tickfont\": {\n",
    "                    \"size\": 10                \n",
    "                }\n",
    "            },\n",
    "            \"template\":'plotly_white'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec08522c",
   "metadata": {},
   "source": [
    "# 4. Categorical + Multivariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec44eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Categorical_Multivarate(df, fea) : \n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x = df[fea].unique(),\n",
    "        y = df.loc[df.Risk_Flag == 0, fea].value_counts().values,\n",
    "        name = 'non_risk',\n",
    "        text = df.loc[df.Risk_Flag == 0, fea].value_counts().values,\n",
    "        marker_color = px.colors.sequential.RdBu[0])\n",
    "    )\n",
    "\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x = df[fea].unique(),\n",
    "        y = df.loc[df.Risk_Flag == 1, fea].value_counts().values,\n",
    "        name = 'risk',\n",
    "        text = df.loc[df.Risk_Flag == 0, fea].value_counts().values,\n",
    "        marker_color = px.colors.sequential.RdBu[7])\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4518e28",
   "metadata": {},
   "source": [
    "# 5. System function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e2783d",
   "metadata": {},
   "source": [
    "## 5.1 Call list of data and merge them to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8282c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_dataframe(filename) : \n",
    "    \n",
    "    doc = pd.read_excel(PATH + filename)\n",
    "    \n",
    "    # Drop value means count \n",
    "    \n",
    "    doc_drop = doc[(doc['대계열'] == '총계') | (doc['중계열'] == '계') | (doc['소계열'] == '계')]\n",
    "    doc.drop(doc_drop.index, inplace = True)\n",
    "    \n",
    "    # Column selection\n",
    "    doc = doc[['대계열', '중계열', '소계열', '전체']]\n",
    "    \n",
    "    # Column processing\n",
    "    doc['전체'].fillna(0, inplace = True)\n",
    "    doc['전체'] = doc['전체'].astype('int64')\n",
    "    year_col = filename.split(\"_\")[0]\n",
    "    doc.rename(columns = {'전체' : year_col}, inplace = True)\n",
    "    \n",
    "    return doc \n",
    "    \n",
    "def generate_dataframe_by_path(PATH) :\n",
    "    \n",
    "    file_list = os.listdir(PATH)\n",
    "    first_doc = True\n",
    "    file_list.sort()\n",
    "    \n",
    "    for file in file_list : \n",
    "        doc = processing_dataframe(file) \n",
    "        if first_doc : \n",
    "            final_doc, first_doc = doc, False\n",
    "        else : \n",
    "            final_doc = pd.merge(final_doc, doc, how = 'outer')\n",
    "    \n",
    "    return final_doc  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
