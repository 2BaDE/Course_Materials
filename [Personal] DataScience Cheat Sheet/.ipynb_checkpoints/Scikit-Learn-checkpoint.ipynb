{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c5f2d1d",
   "metadata": {},
   "source": [
    "# <center> Scikit-Learn Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9981af",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd75e40",
   "metadata": {},
   "source": [
    "## 1.1 Train, Test datsets split\n",
    "We us train_test_split for preventing overfitting problem.   \n",
    "Source : [train_test_split method](https://teddylee777.github.io/scikit-learn/train-test-split)\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(df_train, y, train_size = 0.7, test_size = 0.3, random_state = 17)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24fc8d6",
   "metadata": {},
   "source": [
    "## 1.2 get dummies\n",
    "We use get_dummies to convert categorical variable into dummy/indicator variables.\n",
    "\n",
    "```python\n",
    "df = pd.get_dummies(df, columns = categoricals)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4275a4c",
   "metadata": {},
   "source": [
    "## 1.3 neHotEncoder\n",
    "Same method working same as get_dummies()\n",
    "\n",
    "```python\n",
    "Encoder = OneHotEncoder()\n",
    "\n",
    "Encoder.fit_transform(X_train)\n",
    "Encoder.fit(X_valid)\n",
    "\n",
    "cat_transformer = Pipeline(steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown = 'ignore')),\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab47c19",
   "metadata": {},
   "source": [
    "## 1.4 SimpleImputer\n",
    "변수에 특정한 방법을 적용하여 NaN값을 일괄 처리한다. \n",
    "\n",
    "```python\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "Imputer = SimpleImputer(strategy = 'most_frequent/median/mean')\n",
    "\n",
    "Imputer.fit_transform(X_train) # fit + transform, fit과 transform을 분리해서 사용 가능하다. \n",
    "Imputer.fit(X_valid)\n",
    "\n",
    "cat_transformer = Pipeline(steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown = 'ignore')),\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70043792",
   "metadata": {},
   "source": [
    "## 1.5 polynomial_fit\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31159a69",
   "metadata": {},
   "source": [
    "## 1.6 Scalers\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler\n",
    "X_train_scaled = scaler().fit_transform(X_train)\n",
    "X_holdout_scaled = scaler().fit_trainsform(X_holdout)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bedbc17",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58c1b7c",
   "metadata": {},
   "source": [
    "## 2.1 Mutual information(Discrete features)\n",
    "Discrete features의 상관관계를 파악한다. Continuous features의 Correlation metrics와 동일한 의미를 가지며, 이 metric에서 좋은 점수를 얻지 못한 features는 제외하거나 다른 feature와 상관관계를 확인하여 새로운 변수량을 생성할 필요가 있음. \n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7085c916",
   "metadata": {},
   "source": [
    "## 2.2 Creating Features\n",
    "새로운 변수를 만드는 행위는 매우 중요하다 예를들어 정규화를 이루고 있지 않는 변수를 정규화를 시킨다던가, 더 좋은 상관관계를 가지고 있는 변수를 생성하여 모델에 추가하는 행위는 더욱 생산성을 높임\n",
    "\n",
    "1. Make new columns : df[col3] = df[col1]/df[col2]\n",
    "\n",
    "2. Do powers and logarithms to make datasets gets normalize : df[lgcol] = df[col].apply(np.log)\n",
    "\n",
    "3. Count : Target variable과 상관관계가 높지 않는 변수들을 Count로 묶어 총 몇개가 있는지 표시하거나 Id별로 몇개의 0.0값이 있는지 확인하는 작업, sum() or gt(0).sum()을 사용\n",
    "\n",
    "4. Str 연산자 : Str을 통해 Object type의 Insigth meaning을 추출한다. 예를들어 휴대전화에서 지역을, 혹은 등급+단계에서 각각의 feature로 분리하는 법\n",
    "\n",
    "5. Group transform : Grouping 연산을 한 뒤에 각각을 mapping하여 datasets에 붙이기 보다 tranform을 사용하여 one line code로 비교 dataset feature를 생성한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33e0b79",
   "metadata": {},
   "source": [
    "## 2.3 Cluter Label as a Feature\n",
    "특정 군집화를 하여 그룹을 지정해줌으로써 복잡한 관계를 한 차원 낮게 풀어줄 수 있다. K-means clustering을 적용하며 자연스러운 pandas bin() function으로 category variable을 생성한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a13b0a1",
   "metadata": {},
   "source": [
    "# 3. Model Constructing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0449c348",
   "metadata": {},
   "source": [
    "## 3.1 Pipe line \n",
    "source : https://lsjsj92.tistory.com/579\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "knn_pipe = Pipeline(\n",
    "    [(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier(n_jobs=-1))]\n",
    ")\n",
    "\n",
    "knn_params = {\"knn__n_neighbors\": range(1, 10)}\n",
    "\n",
    "knn_grid = GridSearchCV(knn_pipe, knn_params, cv=5, n_jobs=-1, verbose=True)\n",
    "\n",
    "knn_grid.fit(X_train, y_train)\n",
    "\n",
    "knn_grid.best_params_, knn_grid.best_score_\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a269e813",
   "metadata": {},
   "source": [
    "## 3.2 ColumnTransformer\n",
    "복수의 변수들을 적용할 Preprocessor마다 분산 적용하기 위해 사용.\n",
    "\n",
    "```python\n",
    "# Preprocessing for numerical data\n",
    "\n",
    "num_transformer = Pipeline(steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'median')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "\n",
    "cat_transformer = Pipeline(steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown = 'ignore')),\n",
    "])\n",
    "\n",
    "# Preprocessing for discrete data\n",
    "\n",
    "dis_transformer = Pipeline(steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "# Bundle Preprocessing for all varaibles\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers = [\n",
    "    ('num', num_transformer, num_cols),\n",
    "    ('cat', cat_transformer, cat_cols),\n",
    "    ('dis', dis_transformer, dis_cols)\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54292a7a",
   "metadata": {},
   "source": [
    "## 3.3 Grid Search\n",
    "Grid search is exploratory way to find hyper parameters making best score of model. \n",
    "\n",
    "결론 : 그리드 서치를 하는 이유는 \" 가장 우수한 성능을 보이는 모델의 하이퍼 파라미터를 찾기 위해서 \". 이유는 단순하다. 모든 경우의 수를 때려 넣어보고 가장 성능이 좋게 만드는 모델의 하이퍼 파라미터를 찾는거다. \n",
    "\n",
    "Source : [GridSearchCV](https://huidea.tistory.com/32)\n",
    "\n",
    "```python\n",
    "forest_params = {\"max_depth\": range(6, 12), \"max_features\": range(4, 19)}\n",
    "\n",
    "forest_grid = GridSearchCV(forest, forest_params, cv=5, n_jobs=-1, verbose=True)\n",
    "\n",
    "forest_grid.fit(X_train, y_train)\n",
    "\n",
    "forest_grid.best_params_, forest_grid.best_score_  # ({'max_depth': 9, 'max_features': 6}, 0.951)\n",
    "\n",
    "best_accuracy_model = forest_grid.best_estimator_\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b502826c",
   "metadata": {},
   "source": [
    "# 4. Model library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cfa6c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "# Model Construction\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Model\n",
    "\n",
    "# 1) Linear Prediction\n",
    "\n",
    "# 2) Classification\n",
    "\n",
    "\n",
    "\n",
    "# Model Evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squaared_error, mean_absolute_error \n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
